{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, you'll learn how to evaluate your model results and you'll learn how to select the appropriate features using stepwise selection.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Use stepwise selection methods to determine the most important features for a model\n",
    "* Use recursive feature elimination to determine the most important features for a model\n",
    "\n",
    "## The Boston Housing Data once more\n",
    "\n",
    "We pre-processed the Boston Housing data the same way we did before:\n",
    "\n",
    "- We dropped `'ZN'` and `'NOX'` completely\n",
    "- We categorized `'RAD'` in 3 bins and `'TAX'` in 4 bins\n",
    "- We transformed `'RAD'` and `'TAX'` to dummy variables and dropped the first variable\n",
    "- We used min-max-scaling on `'B'`, `'CRIM'`, and `'DIS'` (and logtransformed all of them first, except `'B'`)\n",
    "- We used standardization on `'AGE'`, `'INDUS'`, `'LSTAT'`, and `'PTRATIO'` (and logtransformed all of them first, except for `'AGE'`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_features = boston_features.drop(['NOX', 'ZN'],axis=1)\n",
    "\n",
    "# First, create bins for based on the values observed. 3 values will result in 2 bins\n",
    "bins = [0,6,  24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# First, create bins for based on the values observed. 4 values will result in 3 bins\n",
    "bins = [0, 270, 360, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix='TAX', drop_first=True)\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix='RAD', drop_first=True)\n",
    "boston_features = boston_features.drop(['RAD', 'TAX'], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
    "\n",
    "age = boston_features['AGE']\n",
    "b = boston_features['B']\n",
    "logcrim = np.log(boston_features['CRIM'])\n",
    "logdis = np.log(boston_features['DIS'])\n",
    "logindus = np.log(boston_features['INDUS'])\n",
    "loglstat = np.log(boston_features['LSTAT'])\n",
    "logptratio = np.log(boston_features['PTRATIO'])\n",
    "\n",
    "# Min-Max scaling\n",
    "boston_features['B'] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features['CRIM'] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "boston_features['DIS'] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "# Standardization\n",
    "boston_features['AGE'] = (age-np.mean(age))/np.sqrt(np.var(age))\n",
    "boston_features['INDUS'] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "boston_features['LSTAT'] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features['PTRATIO'] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(boston.data, columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_(6, 24]</th>\n",
       "      <th>TAX_(270, 360]</th>\n",
       "      <th>TAX_(360, 712]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.704344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.575</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>-1.443977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.153211</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.421</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153134</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.185</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171005</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.998</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250315</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.147</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM     INDUS  CHAS     RM       AGE       DIS   PTRATIO         B  \\\n",
       "0  0.000000 -1.704344   0.0  6.575 -0.120013  0.542096 -1.443977  1.000000   \n",
       "1  0.153211 -0.263239   0.0  6.421  0.367166  0.623954 -0.230278  1.000000   \n",
       "2  0.153134 -0.263239   0.0  7.185 -0.265812  0.623954 -0.230278  0.989737   \n",
       "3  0.171005 -1.778965   0.0  6.998 -0.809889  0.707895  0.165279  0.994276   \n",
       "4  0.250315 -1.778965   0.0  7.147 -0.511180  0.707895  0.165279  1.000000   \n",
       "\n",
       "      LSTAT  RAD_(6, 24]  TAX_(270, 360]  TAX_(360, 712]  \n",
       "0 -1.275260            0               1               0  \n",
       "1 -0.263711            0               0               0  \n",
       "2 -1.627858            0               0               0  \n",
       "3 -2.153192            0               0               0  \n",
       "4 -1.162114            0               0               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for stepwise selection is copied below. Use this function provided on your preprocessed Boston Housing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 9.27989e-122\n",
      "Add  RM                             with p-value 1.98621e-16\n",
      "Add  PTRATIO                        with p-value 2.5977e-12\n",
      "Add  DIS                            with p-value 2.85496e-09\n",
      "Add  B                              with p-value 2.77572e-06\n",
      "Add  INDUS                          with p-value 0.0017767\n",
      "Add  CHAS                           with p-value 0.0004737\n",
      "resulting features:\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'B', 'INDUS', 'CHAS']\n"
     ]
    }
   ],
   "source": [
    "X = boston_features\n",
    "y = pd.DataFrame(boston.target, columns = ['target'])\n",
    "\n",
    "result = stepwise_selection(X, y, verbose=True)\n",
    "print('resulting features:')\n",
    "print(result)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model again in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.770</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   242.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 May 2020</td> <th>  Prob (F-statistic):</th> <td>4.89e-156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:48:05</td>     <th>  Log-Likelihood:    </th> <td> -1464.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   2945.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   2979.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    5.0123</td> <td>    2.829</td> <td>    1.772</td> <td> 0.077</td> <td>   -0.545</td> <td>   10.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -5.6444</td> <td>    0.320</td> <td>  -17.629</td> <td> 0.000</td> <td>   -6.274</td> <td>   -5.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    2.8712</td> <td>    0.388</td> <td>    7.405</td> <td> 0.000</td> <td>    2.109</td> <td>    3.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -1.3564</td> <td>    0.227</td> <td>   -5.983</td> <td> 0.000</td> <td>   -1.802</td> <td>   -0.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -9.7229</td> <td>    1.326</td> <td>   -7.333</td> <td> 0.000</td> <td>  -12.328</td> <td>   -7.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    4.0619</td> <td>    0.934</td> <td>    4.347</td> <td> 0.000</td> <td>    2.226</td> <td>    5.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>   -1.2099</td> <td>    0.334</td> <td>   -3.619</td> <td> 0.000</td> <td>   -1.867</td> <td>   -0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.7988</td> <td>    0.795</td> <td>    3.519</td> <td> 0.000</td> <td>    1.236</td> <td>    4.362</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>105.185</td> <th>  Durbin-Watson:     </th> <td>   1.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 423.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.878</td>  <th>  Prob(JB):          </th> <td>1.03e-92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.124</td>  <th>  Cond. No.          </th> <td>    96.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.773\n",
       "Model:                            OLS   Adj. R-squared:                  0.770\n",
       "Method:                 Least Squares   F-statistic:                     242.7\n",
       "Date:                Sat, 30 May 2020   Prob (F-statistic):          4.89e-156\n",
       "Time:                        16:48:05   Log-Likelihood:                -1464.7\n",
       "No. Observations:                 506   AIC:                             2945.\n",
       "Df Residuals:                     498   BIC:                             2979.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0123      2.829      1.772      0.077      -0.545      10.570\n",
       "LSTAT         -5.6444      0.320    -17.629      0.000      -6.274      -5.015\n",
       "RM             2.8712      0.388      7.405      0.000       2.109       3.633\n",
       "PTRATIO       -1.3564      0.227     -5.983      0.000      -1.802      -0.911\n",
       "DIS           -9.7229      1.326     -7.333      0.000     -12.328      -7.118\n",
       "B              4.0619      0.934      4.347      0.000       2.226       5.898\n",
       "INDUS         -1.2099      0.334     -3.619      0.000      -1.867      -0.553\n",
       "CHAS           2.7988      0.795      3.519      0.000       1.236       4.362\n",
       "==============================================================================\n",
       "Omnibus:                      105.185   Durbin-Watson:                   1.099\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              423.621\n",
       "Skew:                           0.878   Prob(JB):                     1.03e-92\n",
       "Kurtosis:                       7.124   Cond. No.                         96.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_fin = X[result]\n",
    "X_with_intercept = sm.add_constant(X_fin)\n",
    "model = sm.OLS(y, X_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# X_fin = X[result]\n",
    "# X_with_intercept = sm.add_constant(X_fin)\n",
    "# model = sm.OLS(y,X_with_intercept).fit()\n",
    "# model.summary()\n",
    "# # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stepwise procedure mentions that `'INDUS'` was added with a p-value of 0.0017767, but our statsmodels output returns a p-value of 0.000. Use some of the stepwise procedure logic to find the intuition behind this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature ranking to select the 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select= 5)\n",
    "selector = selector.fit(X, y.values.ravel())\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# linreg = LinearRegression()\n",
    "# selector = RFE(linreg, n_features_to_select = 5)\n",
    "# selector = selector.fit(X, y.values.ravel()) # convert y to 1d np array to prevent DataConversionWarning\n",
    "# selector.support_ \n",
    "# # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model again using the 5 selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = X.columns[selector.support_]\n",
    "linreg.fit(X[selected_columns],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_columns = X.columns[selector.support_ ]\n",
    "# linreg.fit(X[selected_columns],y)\n",
    "# # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict $\\hat y$ using your model. You can use `.predict()` in scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = linreg.predict(X[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = linreg.predict(X[selected_columns])\n",
    "\n",
    "# # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the formulas of R-squared and adjusted R-squared below, and your Python/numpy knowledge, compute them and contrast them with the R-squared and adjusted R-squared in your statsmodels output using stepwise selection. Which of the two models would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_{residual} = \\sum (y - \\hat{y})^2 $\n",
    "\n",
    "$SS_{total} = \\sum (y - \\bar{y})^2 $\n",
    "\n",
    "$R^2 = 1- \\dfrac{SS_{residual}}{SS_{total}}$\n",
    "\n",
    "$R^2_{adj}= 1-(1-R^2)\\dfrac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared is  target    0.742981\n",
      "dtype: float64\n",
      "adjusted_r_squared is  target    0.740411\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "SS_residual = np.sum((y-yhat)**2)\n",
    "SS_total = np.sum((y-np.mean(y))**2)\n",
    "r_squared = 1-(float(SS_residual))/SS_total\n",
    "adjusted_r_squared = 1-(1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)\n",
    "print(\"r_squared is \",r_squared)\n",
    "print('adjusted_r_squared is ',adjusted_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS_Residual = np.sum((y-yhat)**2)\n",
    "# SS_Total = np.sum((y-np.mean(y))**2)\n",
    "# r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "# adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1\n",
    "# # Your code here\n",
    "\n",
    "# # r_squared is 0.742981  \n",
    "# # adjusted_r_squared is 0.740411"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform variable selection using forward selection, using this resource: https://planspace.org/20150423-forward_selection_with_statsmodels/. Note that this time features are added based on the adjusted R-squared!\n",
    "- Tweak the code in the `stepwise_selection()` function written above to just perform forward selection based on the p-value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Great! You practiced your feature selection skills by applying stepwise selection and recursive feature elimination to the Boston Housing dataset! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
